{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPURqiPaYdPsBggSt2t6NXw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlscks/pythondemo/blob/main/python_13_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%88%98%EC%A7%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/python_demo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRdw3EWtUwzC",
        "outputId": "415c3355-60e5-4a95-8f21-2b4283ef4bab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/python_demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 크롤링(crawling), 스크래핑(scraping), 파싱(parsing)\n",
        "- 크롤링(crawling) : 웹문서의 하이퍼링크를 타고 들어가는 행위로 스파이더링(spidering)라고도 한다.\n",
        "- 스크래핑(scraping) : 웹 사이트에서 원하는 정보를 추출하는 기술\n",
        "- 파싱(parsing) : 추출한 정보를 분석하는 기술"
      ],
      "metadata": {
        "id": "CX-npn_GMeqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 파이썬에서 제공해주는 크롤링 라이브러리\n",
        "- 2-1 urllib 모듈 : 파이썬에서 내장 모듈\n",
        "- 2-2 requests 모듈 : 외부모듈\n",
        "\n",
        "### 3. 외부 라이브러리\n",
        "- 정적 : BeautifulBoup\n",
        "- 동적 : Selenium\n",
        "\n",
        "### 4. BeautifulSoup\n",
        "- HTML과 XML 문서의 parsing 을 하기 위한 python패키지이므로 이 라이브러리를 이용해 정보를 추출한다.\n",
        "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "- https://beautiful-soup-4.readthedocs.io/en/latest/\n",
        "\n",
        "### 5. Selenium\n",
        "- 'Web Application'의 테스트를 자동화하기 위한 도구이다.\n",
        "- Selenium에서는 웹브라우저를 실행 시킨 후 클릭을 하거나, 텍스트를 입력하고, 지우는 등의 조작에 해당하는 메소드를 지원한다.\n",
        "- 팝업을 닫아줘야만 정상적으로 화면을 볼 수 있는 웹 사이트도 있다.\n",
        " - 그리고 사용하는 이유 중 가장 중요한게 바로 동적 페이지(JavaScript)로 제공하는 HTML인 경우이다.\n",
        " - 크롤링하는 도구는 BeautifulSoup사용하지만 동적으로 제어해주는 도구는 Selenium을 사용한다.\n",
        "\n",
        " - !pip install selenium\n",
        " -- https://www.selenium.dev/\n",
        " - chromdriver.exe. 다운로드\n",
        " -- https://chromedriver.chromium.org/downloads\n",
        "\n",
        "### 6. 크롤러(crawler)\n",
        "- 자동으로 웹 페이지에 있는 정보를 수집하는 프로그램이다.\n",
        "- 크롤러를 '봇', '로봇', '스파이더'라 한다.\n",
        "- 구글 등의 검색 엔진은 봇 크롤러를 사용해 전 세계에 있는 웹 페이지의 정보를 모아서 축적한다. 그리고 사용자가 키워드를 검색하면 축적된 방대한 정보에서 적당히 웹페이지를 찾아서 제공해 준다."
      ],
      "metadata": {
        "id": "bQDru6WxOdUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - 1 urllib 모듈\n",
        "- URL문자열과 웹 요청에 관련된 모듈 5개 제공\n",
        " - urllib.request : URL 문자열을 가지고 요청 기능 제공\n",
        " - urllib.response : urllib 모듈에 의해 사용되는 응답 클래스들 제공\n",
        " - urllib.parse : URL 문자열을 파싱하여 해석하는 기능 제공\n",
        " - urllib.error : urllib.request에 의해 발생하는 예외 클래스 제공\n",
        " - urllib.robotparser : robots.txt파일을 구문 분석하는 기능 제공\n",
        " -[※ robots.txt 링크]([https://seo.tbwakorea.com/blog/robots-txt-complete-guide/])"
      ],
      "metadata": {
        "id": "MRaJIyQIMOia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from urllib.request import urlopen"
      ],
      "metadata": {
        "id": "ygUj2ikMTUkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://www.naver.com'\n",
        "html = urlopen(url)\n",
        "print(html.status) # 응답코드 200 (정상적으로 응답을 받음)\n",
        "print(type(html)) # <class 'http.client.HTTPResponse'>\n",
        "print(dir(html))\n",
        "lines = html.read().decode('utf-8')\n",
        "# print(lines)\n",
        "\n",
        "\n",
        "with open('./urllib_naver.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWfslQJ-Td6C",
        "outputId": "1417eeb7-4e86-4040-cfb3-91fde6f75a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "<class 'http.client.HTTPResponse'>\n",
            "['__abstractmethods__', '__class__', '__del__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__next__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_abc_impl', '_checkClosed', '_checkReadable', '_checkSeekable', '_checkWritable', '_check_close', '_close_conn', '_get_chunk_left', '_method', '_peek_chunked', '_read1_chunked', '_read_and_discard_trailer', '_read_next_chunk_size', '_read_status', '_readall_chunked', '_readinto_chunked', '_safe_read', '_safe_readinto', 'begin', 'chunk_left', 'chunked', 'close', 'closed', 'code', 'debuglevel', 'detach', 'fileno', 'flush', 'fp', 'getcode', 'getheader', 'getheaders', 'geturl', 'headers', 'info', 'isatty', 'isclosed', 'length', 'msg', 'peek', 'read', 'read1', 'readable', 'readinto', 'readinto1', 'readline', 'readlines', 'reason', 'seek', 'seekable', 'status', 'tell', 'truncate', 'url', 'version', 'will_close', 'writable', 'write', 'writelines']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./urllib_naver.txt', 'r') as f:\n",
        " # print(f.read())\n",
        "    print(f.readline()) # 첫 줄이 공백임\n",
        "    print(f.readline())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dd-YQpsTsjB",
        "outputId": "7a075237-82af-460b-9647-e6f5f504ed9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "<!doctype html>                          <html lang=\"ko\" data-dark=\"false\"> <head> <meta charset=\"utf-8\"> <title>NAVER</title> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=1190\"> <meta name=\"apple-mobile-web-app-title\" content=\"NAVER\"/> <meta name=\"robots\" content=\"index,nofollow\"/> <meta name=\"description\" content=\"네이버 메인에서 다양한 정보와 유용한 컨텐츠를 만나 보세요\"/> <meta property=\"og:title\" content=\"네이버\"> <meta property=\"og:url\" content=\"https://www.naver.com/\"> <meta property=\"og:image\" content=\"https://s.pstatic.net/static/www/mobile/edit/2016/0705/mobile_212852414260.png\"> <meta property=\"og:description\" content=\"네이버 메인에서 다양한 정보와 유용한 컨텐츠를 만나 보세요\"/> <meta name=\"twitter:card\" content=\"summary\"> <meta name=\"twitter:title\" content=\"\"> <meta name=\"twitter:url\" content=\"https://www.naver.com/\"> <meta name=\"twitter:image\" content=\"https://s.pstatic.net/static/www/mobile/edit/2016/0705/mobile_212852414260.png\"> <meta name=\"twitter:description\" content=\"네이버 메인에서 다양한 정보와 유용한 컨텐츠를 만나 보세요\"/>  <link rel=\"stylesheet\" href=\"https://pm.pstatic.net/dist/css/nmain.20221110.css\"> <link rel=\"stylesheet\" href=\"https://ssl.pstatic.net/sstatic/search/pc/css/sp_autocomplete_220526.css\"> <link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/favicon.ico?1\"/>  <link rel=\"apple-touch-icon\" sizes=\"114x114\" href=\"https://s.pstatic.net/static/www/u/2014/0328/mma_204243574.png\"/> <link rel=\"apple-touch-icon\" href=\"https://s.pstatic.net/static/www/u/2014/0328/mma_20432863.png\"/> <script>window.nmain=window.nmain||{},window.nmain.supportFlicking=!1;var nsc=\"navertop.v4\",ua=navigator.userAgent,useIeJSFlag=\"1\";window.nmain.isIE=\"0\"===useIeJSFlag,document.getElementsByTagName(\"html\")[0].setAttribute(\"data-useragent\",ua),window.nmain.isIE&&(Object.create=function(n){function a(){}return a.prototype=n,new a})</script> <script>var darkmode= false;window.naver_corp_da=window.naver_corp_da||{main:{}},window.naver_corp_da.main=window.naver_corp_da.main||{},window.naver_corp_da.main.darkmode=darkmode,window.gladsdk=window.gladsdk||{cmd:[]},window.gladsdk.cmd.push((function(){window.gladsdk.setHostMeta(\"theme\",darkmode?\"dark\":\"light\")})),window.ndpsdk=window.ndpsdk||{cmd:[],polyfill:{cmd:[]}},window.ndpsdk.cmd.push((function(){window.ndpsdk.setHostMeta(\"theme\",darkmode?\"dark\":\"light\")}))</script>  <script async src=\"https://ssl.pstatic.net/tveta/libs/glad/prod/gfp-core.js\"></script> <script async src=\"https://ssl.pstatic.net/tveta/libs/ndpsdk/prod/ndp-loader.js\"></script>  <script> window.nmain.gv = {  isLogin: false,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### http.client.HTTPResponse객체의 read() 메서드\n",
        "- read() 메서드를 실행하면 웹 서버가 전달한 데이터 (응답 바디)를 바이트열로 읽어들린다.\n",
        "- 바이트열\n",
        " - 16진수로 이루어진 수열이기 때문에 읽기 어려움으로 웹 서버가 보낸 한글을 포하한 텍스트 형식의 HTML문서의 내용을 읽을 때는 텍스트 형식으로 변환한다.\n",
        " - 바이트열(bytes)의 decode('문자셋')메서드를 실행하여 응답된 문자 셋에 알맞은 문자로 변환한다."
      ],
      "metadata": {
        "id": "Jn_E-Uj1X5jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 웹페이지 인코딩 체크\n",
        "- 웹 크롤링하려는 웹 페이지가 어떠한 문자 셋으로 작성되었는지 파악하는 것이 필수이다.\n",
        " - 페이지의 소스 내용에서 <meta>태그의 charset정보를 체크하면 파악 가능하다.\n",
        " - `<meta charset=\"utf-8\">`\n",
        " - 웹 페이지의 문자 셋 정보를 파이썬 프로그램으로도 파악할 수 있다.\n",
        " -urllib.request.urlopen( ) 함수의 리턴값인 http.client.HTTPResponse 객체의 info() 메소드 호출\n",
        " - http.client.HTTPMessage 객체가 리턴\n",
        " - get_content_charset( )메소드 호출\n",
        " - 문자 셋 정보를 문자열로 리턴 받음"
      ],
      "metadata": {
        "id": "p9K8mY3FiV-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://www.naver.com'\n",
        "f = urllib.request.urlopen(url)\n",
        "print(f)\n",
        "print(dir(type(f.info())))\n",
        "encoding = f.info().get_content_charset()\n",
        "print(encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L_WZU1FjEPD",
        "outputId": "1306b820-0ddc-4448-ea70-4d0cb74f7beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<http.client.HTTPResponse object at 0x7febe6fea5b0>\n",
            "['__bytes__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_params_preserve', 'add_header', 'as_bytes', 'as_string', 'attach', 'del_param', 'get', 'get_all', 'get_boundary', 'get_charset', 'get_charsets', 'get_content_charset', 'get_content_disposition', 'get_content_maintype', 'get_content_subtype', 'get_content_type', 'get_default_type', 'get_filename', 'get_param', 'get_params', 'get_payload', 'get_unixfrom', 'getallmatchingheaders', 'is_multipart', 'items', 'keys', 'raw_items', 'replace_header', 'set_boundary', 'set_charset', 'set_default_type', 'set_param', 'set_payload', 'set_raw', 'set_type', 'set_unixfrom', 'values', 'walk']\n",
            "utf-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2 requests 모듈\n",
        "- Kenneth Reitz에 의해 개발된 파이썬 라이브러리이다.\n",
        "- HTTP 프로토콜과 관련된 기능을 지원한다.\n",
        "- anaconda에서는 site-package로 설치되어 있음\n",
        "- 만약에 필요하면 !pip install requests\n",
        "- requests.request(method, url, **kwargs)에서 제공해주는 함수\n",
        " - method : 요청 방식 지정(GET, POST, HEAD, PUT, DELETE, OPTIONS)\n",
        " - url : 요청할 대상 URL 문자열 지정\n",
        " - params : [선택적]요청시 전달할 Query문자열 지정(딕셔너리, 튜플, 리스트, 바이트열 가능)\n",
        " - data : [선택적]요청시 바디에 담아서 전달할 요청 파라미터 지정(딕셔너리, 튜플, 리스트, 바이트열 가능)\n",
        " - json : [선택적] 요청시 바디에 담아서 전달할 json타입의 객체 지정\n",
        " -auth : [선택적] 인증처리(로그인)에 사용할 튜플 지정\n",
        "- requests, request( )함수에 요청 방식을 지정하여 호출하는 것과 동일한 함수를 지원한다.\n",
        " - requests.get(url, params=None, **kwargs)\n",
        " - requests.post(url, data=None, json=None)\n",
        " - requests.delete(url,**kwargs)\n",
        "- requests.models.Response객체(응답객체)\n",
        " - text\n",
        "   - 문자열 형식으로 응답 컨텐츠 추출\n",
        "   - 추출 시 사용되는 문자셋은 'ISO-8859-1'이므로 'utf-8'이나 'euc-kr' 문자셋으로 작성된 콘텐츠 추출 시 한글이 깨지는 현상 발생\n",
        "   - 추출전 응답되는 컨텐츠의 문자셋 정보를 파악하여 Response객체의 encoding속셍에 문자 셋 정보를 설정한 후 추출\n",
        " - content\n",
        "   - 바이트열 형식으로 응답 콘텐츠 추출\n",
        "   - 응답 콘텐츠가 이미지와 같은 바이너리 형식은 경우 사용\n",
        "   - 한글이 들어간 문자열 형식인 경우 r.content.decode('utf-8')을 사용해서 디코드 해야함"
      ],
      "metadata": {
        "id": "B-9tEjznjCSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'http://www.naver.com'\n",
        "cont = requests.get(url)\n",
        "print(cont) # <Response [200]>\n",
        "print(type(cont)) #<class 'requests.models.Response'>\n",
        "print(dir(cont))\n",
        "print(cont.status_code) #200\n",
        "print(type(cont.text)) #<class 'str'>\n",
        "# print(cont.text) # String 자료형으로 반환\n",
        "print(type(cont.content)) #<class 'bytes'>\n",
        "# print(cont.content) # 바이트열 자료형으로 반환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu9sdr23oCdE",
        "outputId": "acd5954c-97f2-4798-8390-9e87b84468e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "<class 'requests.models.Response'>\n",
            "['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']\n",
            "200\n",
            "<class 'str'>\n",
            "<class 'bytes'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.번외 urllib VS request\n",
        "- urllib\n",
        " - 인코딩하여 바이너리 형태로 데이터 전송\n",
        " - 데이터 전달 방식에 따라 GET요청, POST요청을 구분\n",
        "- requests\n",
        " - 딕셔너리 형태로 데이터 전송\n",
        " - 요청메서드(GET, POST)를 명시하여 요청"
      ],
      "metadata": {
        "id": "u-cE706srCKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-1 BeautifulSoup\n",
        "- HTML 및 XML 파일에서 데이터를 추출하기 위한 파이썬 라이브러리이다.\n",
        "- 파이썬에서 기본적으로 제공하는 라이브러리가 아니므로 별도 설치가 필요하다.\n",
        " - Anaconda에는 BeautifulSoup 패키지가 Site-package로 설치되어 있다.\n",
        " - pip install beautifulSoup4\n",
        "- HTML 및 XML파일의 내용을 읽을 때 다음 파서(Parser)를 이용한다.\n",
        " - html.parser, lxml, lxml-xml, html5lib\n",
        " - 파이썬이 내장하고 있는 파서 사용가능\n",
        " - 좀 더 성능이 좋은 파서를 추가로 설치하여 사용 가능\n",
        " - 파서 라이브러리(Parser Library) 비교   \n",
        "   ![parser](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc28GWb%2FbtqCtX7fBRN%2FnRwJ7DSP8dtjjBxGwfGv10%2Fimg.png)\n",
        "\n",
        "- HTML 파싱\n",
        " - BeautifulSoup의 메인 패키지인 bs패키지에서 BeautifulSoup( )함수 임포트\n",
        " - 파싱할 HTML문서와 파싱에 사용할 파서(구문분석기)를 지정하여 호출\n",
        " - HTML 문서에 대한 파싱이 끝나면 트리구조형식으로 DOM 객체 생성\n",
        "\n",
        "- bs4.BeautifulSoup객체의 태그 접근 방법\n",
        " - HTML문서를 파싱하고 bs4.BeautifulSoup 객체생성\n",
        " - <html>, <head>태그와 <body>태그는 제외하고 접근하려는 태그에 계층 구조를 적용\n",
        "    \n",
        "    - 태그명을 (.)연산자와 함께 사용\n",
        "    \n",
        "     - bs.태그명\n",
        "     - bs.태그명.태그명\n",
        "     - bs.태그명.태그명.태그명\n",
        "     - bs.html.body.h1\n",
        "- bs4.element.Tag 객체의 주요 속성과 메서드\n",
        " - 태그명 속출\n",
        "   - bs.태그명.name\n",
        "  -속성 속출\n",
        "    - bs.태그명['속성명']\n",
        "    - bs.태그명.attrs\n",
        "  - 콘텐츠 추출\n",
        "   - bs.태그명.string\n",
        "   - bs.태그명.text\n",
        "   - bs.태그명.contents\n",
        "   - bs.태그명.strings\n",
        "   - bs.태그명.get_text()\n",
        "- 태그로 부터 다른 태그로 이동\n",
        " - 부모 태그 추출\n",
        "   - bs.태그명.parent\n",
        "  - 자식 태그들 추출\n",
        "    - bs.태그명.children\n",
        "  - 형제 태그 추출\n",
        "    - bs.태그명.next_sibling\n",
        "    - bs.태그명.previous_sibling\n",
        "    - bs.태그명.next_siblings\n",
        "    - bs.태그명.previous_siblings\n",
        "  - 자손 태그들 속출\n",
        "    - bs.태그명.descendants\n",
        "\n",
        "- bs4.BeautifulSoup 객체의 주요 메서드\n",
        "  - HTML 문서에 대한 파싱이 끝나고 생성된 트리 구조 형식의 DOM객체\n",
        "  - 태그 찾기 기능의 주요 메서드\n",
        "    - find_all( ) 3버전 => findAll() 2버전\n",
        "    - find( )\n",
        "    - select ( )\n",
        "    - find_parents( ) 및 find_parent( )\n",
        "    - find_next_siblings( ) 및 find_next_sibling( )\n",
        "    - find_previous_siblings( ) 및 find_previous_sibling( )\n",
        "    - find_all_next( ) 및 find_next( )\n",
        "    - first_all_previous( ) 및 first_previous( )\n",
        " "
      ],
      "metadata": {
        "id": "SiaPxmbqttdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bs.find( )\n",
        "- 주어진 기준에 맞는 태그 한 개만 리턴\n",
        "- 결과는 존재하면 bs4.element.Tag 리턴하고 없으면 None을 리턴한다.\n",
        "- find()는 find_all()에 limit=1로 설정한 것과 동일하게 수행\n"
      ],
      "metadata": {
        "id": "U2jMSKaRy6zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import bs4\n",
        "\n",
        "url = 'http://www.naver.com'\n",
        "res = requests.get(url)\n",
        "#print(res.text)\n",
        "\n",
        "#BeautifulSoup(parsing할 데이터, parsing방법)\n",
        "# res.text를 html으로 파싱\n",
        "bs_obj2 = bs4.BeautifulSoup(res.text, 'html.parser')\n",
        "#print(bs_obj2)\n",
        "print(bs_obj2.find('div')) # 첫번째 div를 호출함\n",
        "\n",
        "print('------------------------------')\n",
        "bs_obj3 = bs4.BeautifulSoup(res.text, 'lxml')\n",
        "print(type(bs_obj3)) # <class 'bs4.BeautifulSoup'>\n",
        "print(type(bs_obj3.find('div'))) #<class 'bs4.element.Tag'>\n",
        "print(bs_obj3.find('xk')) # 결과값이 없으면 None으로 리턴\n",
        "bs_obj3.find('div')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkL1W_97tz1Y",
        "outputId": "0e9fb0e9-de1c-4f57-c430-046f770e6556"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div id=\"u_skip\"> <a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a> <a href=\"#themecast\"><span>주제별캐스트 바로가기</span></a> <a href=\"#timesquare\"><span>타임스퀘어 바로가기</span></a> <a href=\"#shopcast\"><span>쇼핑캐스트 바로가기</span></a> <a href=\"#account\"><span>로그인 바로가기</span></a> </div>\n",
            "------------------------------\n",
            "<class 'bs4.BeautifulSoup'>\n",
            "<class 'bs4.element.Tag'>\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<div id=\"u_skip\"> <a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a> <a href=\"#themecast\"><span>주제별캐스트 바로가기</span></a> <a href=\"#timesquare\"><span>타임스퀘어 바로가기</span></a> <a href=\"#shopcast\"><span>쇼핑캐스트 바로가기</span></a> <a href=\"#account\"><span>로그인 바로가기</span></a> </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 소스 예제"
      ],
      "metadata": {
        "id": "4EIAcKVo2IiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "\n",
        "html_str = \"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "  <body>\n",
        "   <ul class=\"ko\">\n",
        "     <li>\n",
        "        <a href = \"https://www.naver.com\"> 네이버</a>\n",
        "     </li>\n",
        "\n",
        "     <li>\n",
        "        <a href = \"https://www.daum.net\"> 다음</a>\n",
        "     </li>\n",
        "   </ul>\n",
        "\n",
        "   <ul class=\"sns\">\n",
        "     <li>\n",
        "       <a href=\"https://www.google.com\">구글</a>\n",
        "     </li>\n",
        "     <li>\n",
        "       <a href=\"https://www.facebook.com\">페이스북</a>\n",
        "     </li>\n",
        "   </ul>\n",
        "    <div id =\"result>page</div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "G9c_P79w2L2S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs_obj = bs4.BeautifulSoup(html_str, 'html.parser')"
      ],
      "metadata": {
        "id": "tsndJbMJ2Us6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### find()"
      ],
      "metadata": {
        "id": "VfCcu8eH4Iga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(bs_obj)) #<class 'bs4.BeautifulSoup'>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpZq35SD4L76",
        "outputId": "6886f8d2-e516-48d9-bd2c-63a0d116c2b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'bs4.BeautifulSoup'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(bs_obj.find('div')) #<div =\"result=\"\" id=\"\">page</div>\n",
        "print(type(bs_obj.find('div'))) #<class 'bs4.element.Tag'>\n",
        "print(dir(bs_obj.find('div')))\n",
        "print(bs_obj.find('div').text) #page"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_Y4TjpC4fuY",
        "outputId": "2d1edaf6-bf9e-4721-88da-70f4a55b01db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div =\"result=\"\" id=\"\">page</div>\n",
            "<class 'bs4.element.Tag'>\n",
            "['HTML_FORMATTERS', 'XML_FORMATTERS', '__bool__', '__call__', '__class__', '__contains__', '__copy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_all_strings', '_attr_value_as_string', '_attribute_checker', '_find_all', '_find_one', '_formatter_for_name', '_is_xml', '_lastRecursiveChild', '_last_descendant', '_select_debug', '_selector_combinators', '_should_pretty_print', '_tag_name_matches_and', 'append', 'attribselect_re', 'attrs', 'can_be_empty_element', 'childGenerator', 'children', 'clear', 'contents', 'decode', 'decode_contents', 'decompose', 'descendants', 'encode', 'encode_contents', 'extract', 'fetchNextSiblings', 'fetchParents', 'fetchPrevious', 'fetchPreviousSiblings', 'find', 'findAll', 'findAllNext', 'findAllPrevious', 'findChild', 'findChildren', 'findNext', 'findNextSibling', 'findNextSiblings', 'findParent', 'findParents', 'findPrevious', 'findPreviousSibling', 'findPreviousSiblings', 'find_all', 'find_all_next', 'find_all_previous', 'find_next', 'find_next_sibling', 'find_next_siblings', 'find_parent', 'find_parents', 'find_previous', 'find_previous_sibling', 'find_previous_siblings', 'format_string', 'get', 'getText', 'get_attribute_list', 'get_text', 'has_attr', 'has_key', 'hidden', 'index', 'insert', 'insert_after', 'insert_before', 'isSelfClosing', 'is_empty_element', 'known_xml', 'name', 'namespace', 'next', 'nextGenerator', 'nextSibling', 'nextSiblingGenerator', 'next_element', 'next_elements', 'next_sibling', 'next_siblings', 'parent', 'parentGenerator', 'parents', 'parserClass', 'parser_class', 'prefix', 'preserve_whitespace_tags', 'prettify', 'previous', 'previousGenerator', 'previousSibling', 'previousSiblingGenerator', 'previous_element', 'previous_elements', 'previous_sibling', 'previous_siblings', 'quoted_colon', 'recursiveChildGenerator', 'renderContents', 'replaceWith', 'replaceWithChildren', 'replace_with', 'replace_with_children', 'select', 'select_one', 'setup', 'string', 'strings', 'stripped_strings', 'tag_name_re', 'text', 'unwrap', 'wrap']\n",
            "page\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ulEle = bs_obj.find('ul')\n",
        "print(ulEle)\n",
        "print('-------------------')\n",
        "ul_li = ulEle.find('li')\n",
        "print(ul_li)\n",
        "print(type(ul_li))  #<class 'bs4.element.Tag'>\n",
        "print(ul_li.text)  # 네이버"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3878osf5Wno",
        "outputId": "c6a834b4-d8ff-4a1e-8782-e89d29b4f79b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<ul class=\"ko\">\n",
            "<li>\n",
            "<a href=\"https://www.naver.com\"> 네이버</a>\n",
            "</li>\n",
            "<li>\n",
            "<a href=\"https://www.daum.net\"> 다음</a>\n",
            "</li>\n",
            "</ul>\n",
            "-------------------\n",
            "<li>\n",
            "<a href=\"https://www.naver.com\"> 네이버</a>\n",
            "</li>\n",
            "<class 'bs4.element.Tag'>\n",
            "\n",
            " 네이버\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### find_all( )\n",
        "- 주어진 기준에 맞는 모든 태그들을 가져옴\n",
        "- 결과는 bs4.element.ResultSet 객체로 리턴\n",
        "- 호출 방법\n",
        " - find_all('div')\n",
        " - find_all(['p', 'img'])\n",
        " - find_all(True)\n",
        " - find_all(re.compile('^b'))\n",
        " - find_all(id= 'link')\n",
        " - find_all(src=re.compile('png$'), id='fid')\n",
        " - find_all('a', limit=2)"
      ],
      "metadata": {
        "id": "xMgcNAZq6ZCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6sXhUyH5cvI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}